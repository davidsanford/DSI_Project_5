{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling the Madelon Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain\n",
    "\n",
    "The goal in this project was to create a data analysis pipeline.  The pipeline will have consistent elemental steps used to read data from a remote SQL data base, initial benchmarking, feature selection, model selection, and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "In this project I worked with the Madelon data set, a synthetic data set with many variables and a high degree of non-linearity.  It contains 500 features and a binary classification label (-1,1), which I rescale to (0,1).  There are a total of 2000 entries, divided evenly between the two labels.  According to the source website (), the data set has a high degree of non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "My goal in this project was to produce a model which accurately predicts the labels in the Madelon data set.  As the data is highly non-linear, this required significant feature selection and model selection.  I implemented three separate analysis pipelines, corresponding to an initial benchmark using logistic regression, feature selection using a logistic regression with lasso regularization, and the final model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    "\n",
    "In constructing the pipeline, I constructed four key wrapper functions.\n",
    "\n",
    "    load_data_from_database | Accesses the database and saves the data from the 'dsi' table in 'data'.\n",
    "                            |\n",
    "    make_data_dict          | Generates features and labels, then splits into training and validation sets.  The\n",
    "                            | default split is 70% training/30% validations, and a random seed was used throughout\n",
    "                            | to ensure the same split in the notebook used for each step.\n",
    "                            |\n",
    "    general_transformer     | Performs an arbitrary transformation on the training set, then applies that\n",
    "                            | transformation to the validation set.\n",
    "                            |\n",
    "    general_model           | Fits and score an arbitrary model, with any model inputs defined in the model before\n",
    "                            | it is passed to the function.\n",
    "\n",
    "The first two functions have the same inputs/outputs in all three steps, but the last two function have different inputs/outputs in each step:\n",
    "\n",
    "    Step 1: Benchmarking        | general_transformer is used for normalization, general_model takes in an\n",
    "                                | unregularized logistic regression\n",
    "                                |\n",
    "    Step 2: Feature Selection   | general_transformer is used for normalization, general_model takes in a series of\n",
    "                                | logistic regressions with different Lasso regularization weights\n",
    "                                |\n",
    "    Step 3: Model Selection     | general_transformer is used for normalization and selecting the 'k' best \n",
    "                                | features, general_model takes in a set of grid search objects corresponding to\n",
    "                                | l2-regularized logistic regressions, k-nearest neighbors classifiers, and SVC\n",
    "                                | classifiers\n",
    "\n",
    "Ultimately, the benchmark in step 1 will be used as a baseline for the feature selection in step 2.  The best results for the reduced number of features from step 2 will be used for the SelectKBest reduction in step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric\n",
    "\n",
    "I considered the accuracy as the significant metric for this project.  Since the data is equally split between two labels, the baseline accuracy is 50% so no other metric is inherently well-suited in comparison to accuracy.  Moreover, since the data set is synthetic, there is no obvious metric which is inherently desireable for field-specific reason.  In this scenario, accuracy is the easiest metric to extract meaning from, so I will use it throughout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Step 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Step 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Step 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Comparison of Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
