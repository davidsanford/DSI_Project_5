{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and Data\n",
    "\n",
    "Here I am working with the Madelon data set, a synthetic data set with many variables and a high degree of non-linearity.  I will use a limited number of features for training the full model selected using the SelectKBest function, using kBest = [2, 8, 30] as determined in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Here I intend to perform a series of grid searches to obtain a better predictor for the Madelon data set.  I will consider not only the Logistic Regression method used in the previous step, but also k-nearest neighbors and SVC classifiers.  Given the highly non-linear behavior of the Madelon data set, these classifiers may provide better accuracy than the linear logistic regression classifier.  I hope to significantly improve upon the low accuracies found in the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    "\n",
    "Beyond the pipeline used in the previous section, here the data set must be further split.  The SelectKBest transformation is applied in a loop, each time creating a copy of the original data frame to train upon.  Then, each model is applied in a GridSearchCV object, with a range of chosen parameters.  The accuracies of the best models upon the training set are displayed below, and the best was selected to be re-fit and have its performance tested on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib.project_5 import load_data_from_database, make_data_dict, general_model, general_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = load_data_from_database()\n",
    "data_dict = make_data_dict(data, rand_seed = 742)\n",
    "data_dict = general_transformer(StandardScaler(), data_dict)\n",
    "\n",
    "kBest = [2,8,30]\n",
    "\n",
    "data_dicts = []\n",
    "\n",
    "for k in kBest:\n",
    "    l2_weights = [1,0.5,0.2,0.1,0.05,0.04,0.03,0.02,0.01]\n",
    "    k_dict = general_transformer(SelectKBest(k = k), data_dict.copy())\n",
    "\n",
    "    logistic_params = {'C' : l2_weights}\n",
    "    logistic_grid = GridSearchCV(LogisticRegression(penalty='l2',solver='liblinear',fit_intercept=True),\n",
    "                                 param_grid=logistic_params)\n",
    "    this_dict = general_model(k_dict.copy(), logistic_grid)\n",
    "    this_dict['name'] = \"Logistic_\"+str(k)+\"_Features\"\n",
    "    data_dicts.append(this_dict)\n",
    "\n",
    "    knn_params = {'n_neighbors' : [1,3,5,11,21,51],'weights':['uniform','distance'],'p':[1,2]}\n",
    "    knn_grid = GridSearchCV(KNeighborsClassifier(),param_grid=knn_params)\n",
    "    this_dict = general_model(k_dict.copy(), knn_grid)\n",
    "    this_dict['name'] = \"KNN_\"+str(k)+\"_Features\"\n",
    "    data_dicts.append(this_dict)\n",
    "\n",
    "    svc_penalty = [1e3,3e2,1e2,30,10,3,1,3e-1,1e-1,3e-2,1e-2,3e-3,1e-3]\n",
    "    svc_params = {'C' : l2_weights,'kernel':['rbf','sigmoid']}\n",
    "    svc_grid = GridSearchCV(SVC(),param_grid=svc_params)\n",
    "    this_dict = general_model(k_dict.copy(), svc_grid)\n",
    "    this_dict['name'] = \"SVC_\"+str(k)+\"_Features\"\n",
    "    data_dicts.append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_2_Features</td>\n",
       "      <td>0.619287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN_2_Features</td>\n",
       "      <td>0.600705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC_2_Features</td>\n",
       "      <td>0.606486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_8_Features</td>\n",
       "      <td>0.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_8_Features</td>\n",
       "      <td>0.820713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_8_Features</td>\n",
       "      <td>0.752839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic_30_Features</td>\n",
       "      <td>0.632772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN_30_Features</td>\n",
       "      <td>0.757900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC_30_Features</td>\n",
       "      <td>0.711482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Accuracy\n",
       "0   Logistic_2_Features  0.619287\n",
       "1        KNN_2_Features  0.600705\n",
       "2        SVC_2_Features  0.606486\n",
       "3   Logistic_8_Features  0.599976\n",
       "4        KNN_8_Features  0.820713\n",
       "5        SVC_8_Features  0.752839\n",
       "6  Logistic_30_Features  0.632772\n",
       "7       KNN_30_Features  0.757900\n",
       "8       SVC_30_Features  0.711482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame([{\"Name\":data_dicts[i]['name'],\n",
    "               \"Accuracy\":data_dicts[i]['metrics'][0].iloc[0,1]}\n",
    "              for i in range(len(data_dicts))])[[\"Name\",\"Accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='distance')\n"
     ]
    }
   ],
   "source": [
    "print \"Best Model:\\n\",data_dicts[4]['models'][0].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Cross-Validation</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.822126</td>\n",
       "      <td>0.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.889160</td>\n",
       "      <td>0.794870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>0.818841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.755853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.819776</td>\n",
       "      <td>0.786087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score  Cross-Validation  Validation\n",
       "0   accuracy          0.822126    0.795000\n",
       "1    roc_auc          0.889160    0.794870\n",
       "2  precision          0.835556    0.818841\n",
       "3     recall          0.806016    0.755853\n",
       "4         f1          0.819776    0.786087"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_dict = general_transformer(SelectKBest(k = 8), data_dict.copy())\n",
    "best_dict = general_model(k_dict.copy(), data_dicts[4]['models'][0].best_estimator_,test_scores=True)\n",
    "best_dict['metrics'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric\n",
    "\n",
    "Using accuracy for the same reasons as described in the previous steps, the best model is a k-Nearest Neighbors model using 8 features, considering the 5 closest neighbors weighted according to the euclidian distance between points.  It has an accuracy of 82.2% on the training set, and 79.5% on the validation set.  The minor discrepancy with the above table is probably due to a mis-match of random seeds.\n",
    "\n",
    "The performance of the other metrics is similar, showing training scores between 0.8 and 0.9 with only moderate reduction when the model is applied to the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "\n",
    "Using the full pipeline and a broader selection of classification models than a simple logistic regression, I have identified a model which improves significantly on the baseline accuracy.  A naive logistic regression on the Madelon data set produced only 53.6% accuracy on the training set itself, only marginally better than the baseline accuracy of 50%.  In contrast, a k-Nearest Neighbors model selected using a grid search using only a sub-set of the data improved upon this significantly, generating a 79.5% accuracy on the validation set.\n",
    "\n",
    "On a conceptual level, the Madelon data set has significant non-linearity, so it is unsurprising that the logistic regression models performed poorly.  SVC and k-Nearest Neighbors classifiers had signficantly better performance not only for 8 features, but also for 30, with the latter possessing higher accuracy.  This may imply that the data is meaningfully clustered such that both SVC and k-Nearest Neighbors are meaningful models, but does not contain the degree of separation between classes that is required for support vectors to provide good results for that classification scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Implement the following code pipeline using the functions you write in `lib/project_5.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/build_model.png\" width=\"600px\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
